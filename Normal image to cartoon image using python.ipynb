{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PART I - Style Transfer with Gradio UI\n",
        "###- An open source python library that allows you to demo your machine learning model with a friendly web interface"
      ],
      "metadata": {
        "id": "3FthlHXKfd0v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PART I - Style Transfer with Gradio UI"
      ],
      "metadata": {
        "id": "6v3cKjAoJew4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio huggingface_hub\n",
        "###Hugging Face is a community and data science platform that provides:\n",
        "##Tools that enable users to build, train and deploy ML models based on open source (OS) code and technologies\n"
      ],
      "metadata": {
        "id": "ZLdS57vYfo1f",
        "outputId": "e3050b26-5184-4616-d15f-3a83bf2ab2a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gradio\n",
            "  Downloading gradio-3.9-py3-none-any.whl (11.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.6 MB 5.3 MB/s \n",
            "\u001b[?25hCollecting huggingface_hub\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 55.6 MB/s \n",
            "\u001b[?25hCollecting pycryptodome\n",
            "  Downloading pycryptodome-3.15.0-cp35-abi3-manylinux2010_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 45.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from gradio) (1.3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from gradio) (2.11.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from gradio) (7.1.2)\n",
            "Collecting markdown-it-py[linkify,plugins]\n",
            "  Downloading markdown_it_py-2.1.0-py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 3.8 MB/s \n",
            "\u001b[?25hCollecting uvicorn\n",
            "  Downloading uvicorn-0.19.0-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 2.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from gradio) (3.8.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.7/dist-packages (from gradio) (2022.10.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from gradio) (3.2.2)\n",
            "Collecting ffmpy\n",
            "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from gradio) (1.21.6)\n",
            "Collecting websockets\n",
            "  Downloading websockets-10.4-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 56.3 MB/s \n",
            "\u001b[?25hCollecting python-multipart\n",
            "  Downloading python-multipart-0.0.5.tar.gz (32 kB)\n",
            "Collecting paramiko\n",
            "  Downloading paramiko-2.12.0-py2.py3-none-any.whl (213 kB)\n",
            "\u001b[K     |████████████████████████████████| 213 kB 52.1 MB/s \n",
            "\u001b[?25hCollecting h11<0.13,>=0.11\n",
            "  Downloading h11-0.12.0-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.9 MB/s \n",
            "\u001b[?25hCollecting fastapi\n",
            "  Downloading fastapi-0.86.0-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 4.3 MB/s \n",
            "\u001b[?25hCollecting httpx\n",
            "  Downloading httpx-0.23.0-py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 3.8 MB/s \n",
            "\u001b[?25hCollecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from gradio) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gradio) (2.23.0)\n",
            "Collecting orjson\n",
            "  Downloading orjson-3.8.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (272 kB)\n",
            "\u001b[K     |████████████████████████████████| 272 kB 29.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pydantic in /usr/local/lib/python3.7/dist-packages (from gradio) (1.10.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (4.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (3.8.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (4.13.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->huggingface_hub) (3.0.9)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (4.0.2)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (0.13.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (6.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (1.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (22.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (1.8.1)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (2.1.1)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp->gradio) (2.10)\n",
            "Collecting starlette==0.20.4\n",
            "  Downloading starlette-0.20.4-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.9 MB/s \n",
            "\u001b[?25hCollecting anyio<5,>=3.4.0\n",
            "  Downloading anyio-3.6.2-py3-none-any.whl (80 kB)\n",
            "\u001b[K     |████████████████████████████████| 80 kB 12.0 MB/s \n",
            "\u001b[?25hCollecting sniffio>=1.1\n",
            "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
            "Collecting rfc3986[idna2008]<2,>=1.3\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from httpx->gradio) (2022.9.24)\n",
            "Collecting httpcore<0.16.0,>=0.15.0\n",
            "  Downloading httpcore-0.15.0-py3-none-any.whl (68 kB)\n",
            "\u001b[K     |████████████████████████████████| 68 kB 8.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface_hub) (3.10.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->gradio) (2.0.1)\n",
            "Collecting mdurl~=0.1\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Collecting mdit-py-plugins\n",
            "  Downloading mdit_py_plugins-0.3.1-py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 5.5 MB/s \n",
            "\u001b[?25hCollecting linkify-it-py~=1.0\n",
            "  Downloading linkify_it_py-1.0.3-py3-none-any.whl (19 kB)\n",
            "Collecting uc-micro-py\n",
            "  Downloading uc_micro_py-1.0.1-py3-none-any.whl (6.2 kB)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->gradio) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->gradio) (2022.6)\n",
            "Collecting cryptography>=2.5\n",
            "  Downloading cryptography-38.0.3-cp36-abi3-manylinux_2_24_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 55.1 MB/s \n",
            "\u001b[?25hCollecting bcrypt>=3.1.3\n",
            "  Downloading bcrypt-4.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (593 kB)\n",
            "\u001b[K     |████████████████████████████████| 593 kB 75.9 MB/s \n",
            "\u001b[?25hCollecting pynacl>=1.0.1\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "\u001b[K     |████████████████████████████████| 856 kB 62.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.5->paramiko->gradio) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.5->paramiko->gradio) (2.21)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gradio) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gradio) (3.0.4)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from uvicorn->gradio) (7.1.2)\n",
            "Building wheels for collected packages: ffmpy, python-multipart\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4709 sha256=e48ca0eda323c77a4abdd6e144c0adf3b6cfcdc9d2e09de7a904283a99421181\n",
            "  Stored in directory: /root/.cache/pip/wheels/13/e4/6c/e8059816e86796a597c6e6b0d4c880630f51a1fcfa0befd5e6\n",
            "  Building wheel for python-multipart (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-multipart: filename=python_multipart-0.0.5-py3-none-any.whl size=31676 sha256=8e5f73bb5299124f632b0941028d432661cf9b98665703b8d394220b5b399031\n",
            "  Stored in directory: /root/.cache/pip/wheels/2c/41/7c/bfd1c180534ffdcc0972f78c5758f89881602175d48a8bcd2c\n",
            "Successfully built ffmpy python-multipart\n",
            "Installing collected packages: sniffio, mdurl, uc-micro-py, rfc3986, markdown-it-py, h11, anyio, starlette, pynacl, mdit-py-plugins, linkify-it-py, httpcore, cryptography, bcrypt, websockets, uvicorn, python-multipart, pydub, pycryptodome, paramiko, orjson, httpx, ffmpy, fastapi, huggingface-hub, gradio\n",
            "Successfully installed anyio-3.6.2 bcrypt-4.0.1 cryptography-38.0.3 fastapi-0.86.0 ffmpy-0.3.0 gradio-3.9 h11-0.12.0 httpcore-0.15.0 httpx-0.23.0 huggingface-hub-0.10.1 linkify-it-py-1.0.3 markdown-it-py-2.1.0 mdit-py-plugins-0.3.1 mdurl-0.1.2 orjson-3.8.1 paramiko-2.12.0 pycryptodome-3.15.0 pydub-0.25.1 pynacl-1.5.0 python-multipart-0.0.5 rfc3986-1.5.0 sniffio-1.3.0 starlette-0.20.4 uc-micro-py-1.0.1 uvicorn-0.19.0 websockets-10.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RrgXx5voJcvc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PART II - Style Transfer with specialized VToonify-D model"
      ],
      "metadata": {
        "id": "p3VqeBOyqNWC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQ6XEmlHlXbk",
        "outputId": "ed1c44bd-980e-463e-e6b8-d54dc2ffdde6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'VToonify'...\n",
            "remote: Enumerating objects: 655, done.\u001b[K\n",
            "remote: Counting objects: 100% (257/257), done.\u001b[K\n",
            "remote: Compressing objects: 100% (153/153), done.\u001b[K\n",
            "remote: Total 655 (delta 191), reused 153 (delta 104), pack-reused 398\u001b[K\n",
            "Receiving objects: 100% (655/655), 21.13 MiB | 33.50 MiB/s, done.\n",
            "Resolving deltas: 100% (259/259), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/williamyang1991/VToonify.git $CODE_DIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3Hc2FYAzwMW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64665b6b-5b2d-44ce-c399-7938d1a1d5d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-09 04:46:55--  https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/1335132/d2f252e2-9801-11e7-9fbf-bc7b4e4b5c83?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221109%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221109T044656Z&X-Amz-Expires=300&X-Amz-Signature=cd8478212683883b1b9f37da7e630717e910a95de1c53c07e772cfa3f0d0c9ae&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=1335132&response-content-disposition=attachment%3B%20filename%3Dninja-linux.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-11-09 04:46:56--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/1335132/d2f252e2-9801-11e7-9fbf-bc7b4e4b5c83?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221109%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221109T044656Z&X-Amz-Expires=300&X-Amz-Signature=cd8478212683883b1b9f37da7e630717e910a95de1c53c07e772cfa3f0d0c9ae&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=1335132&response-content-disposition=attachment%3B%20filename%3Dninja-linux.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 77854 (76K) [application/octet-stream]\n",
            "Saving to: ‘ninja-linux.zip’\n",
            "\n",
            "ninja-linux.zip     100%[===================>]  76.03K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2022-11-09 04:46:56 (1.76 MB/s) - ‘ninja-linux.zip’ saved [77854/77854]\n",
            "\n",
            "Archive:  ninja-linux.zip\n",
            "  inflating: /usr/local/bin/ninja    \n",
            "update-alternatives: using /usr/local/bin/ninja to provide /usr/bin/ninja (ninja) in auto mode\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9674 sha256=f0f7aded3fad3631aa8728abb0461327a15a0cf0f2222c52c2f738f5f57f4f02\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n",
        "!sudo unzip ninja-linux.zip -d /usr/local/bin/\n",
        "!sudo update-alternatives --install /usr/bin/ninja ninja /usr/local/bin/ninja 1 --force\n",
        "!pip install wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23baccYQlU9E"
      },
      "outputs": [],
      "source": [
        "os.chdir(f'./{CODE_DIR}')\n",
        "MODEL_DIR = os.path.join(os.path.dirname(os.getcwd()), CODE_DIR, 'checkpoint')\n",
        "DATA_DIR = os.path.join(os.path.dirname(os.getcwd()), CODE_DIR, 'data')\n",
        "OUT_DIR = os.path.join(os.path.dirname(os.getcwd()), CODE_DIR, 'output')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d13v7In0kTJn"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import sys\n",
        "sys.path.append(\".\")\n",
        "sys.path.append(\"..\")\n",
        "\n",
        "import argparse\n",
        "import numpy as np\n",
        "import cv2\n",
        "import dlib\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from model.vtoonify import VToonify\n",
        "from model.bisenet.model import BiSeNet\n",
        "from model.encoder.align_all_parallel import align_face\n",
        "from util import save_image, load_image, visualize, load_psp_standalone, get_video_crop_parameter, tensor2cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSnjlBZOkTJ0"
      },
      "outputs": [],
      "source": [
        "def get_download_model_command(file_id, file_name):\n",
        "    \"\"\" Get wget download command for downloading the desired model and save to directory ../checkpoint/. \"\"\"\n",
        "    current_directory = os.getcwd()\n",
        "    save_path = MODEL_DIR\n",
        "    if not os.path.exists(save_path):\n",
        "        os.makedirs(save_path)\n",
        "    url = r\"\"\"wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id={FILE_ID}' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id={FILE_ID}\" -O {SAVE_PATH}/{FILE_NAME} && rm -rf /tmp/cookies.txt\"\"\".format(FILE_ID=file_id, FILE_NAME=file_name, SAVE_PATH=save_path)\n",
        "    return url\n",
        "\n",
        "MODEL_PATHS = {\n",
        "    \"encoder\": {\"id\": \"1NgI4mPkboYvYw3MWcdUaQhkr0OWgs9ej\", \"name\": \"encoder.pt\"},\n",
        "    \"faceparsing\": {\"id\": \"1jY0mTjVB8njDh6e0LP_2UxuRK3MnjoIR\", \"name\": \"faceparsing.pth\"},\n",
        "    \"arcane_exstyle\": {\"id\": \"1TC67wRJkdmNRZTqYMUEFkrhWRKKZW40c\", \"name\": \"exstyle_code.npy\"},\n",
        "    \"caricature_exstyle\": {\"id\": \"1xr9sx_WmRYJ4qHGTtdVQCSxSo4HP3-ip\", \"name\": \"exstyle_code.npy\"},\n",
        "    \"cartoon_exstyle\": {\"id\": \"1BuCeLk3ASZcoHlbfT28qNru4r5f-hErr\", \"name\": \"exstyle_code.npy\"},\n",
        "    \"pixar_exstyle\": {\"id\": \"1yTaKuSrL7I0i0RYEEK5XD6GI-y5iNUbj\", \"name\": \"exstyle_code.npy\"},\n",
        "    \"arcane000\": {\"id\": \"1pF4fJ8acmawMsjjXo4HXRIOXeZR8jLVh\", \"name\": \"generator.pt\"},\n",
        "    \"arcane077\": {\"id\": \"16rLTF2oC0ZeurnM6hjrfrc8BxtW8P8Qf\", \"name\": \"generator.pt\"},\n",
        "    \"caricature039\": {\"id\": \"1C1E4WEoDWzl0nAxR9okKffFmlMOENbeF\", \"name\": \"generator.pt\"},\n",
        "    \"caricature068\": {\"id\": \"1B1ko1x8fX2aJ4BYCL12AnknVAi3qQc8W\", \"name\": \"generator.pt\"},\n",
        "    \"cartoon026\": {\"id\": \"1YJYODh_vEyUrL0q02okjcicpJhdYY8An\", \"name\": \"generator.pt\"},\n",
        "    \"cartoon299\": {\"id\": \"101qMUMfcI2qDxEbfCBt5mOg2aSqdTaIt\", \"name\": \"generator.pt\"},\n",
        "    \"pixar052\": {\"id\": \"16j_l1x0DD0PjwO8YdplAk69sh3-v95rr\", \"name\": \"generator.pt\"},\n",
        "    \"cartoon\": {\"id\": \"11s0hwhZWTLacMAzZH4OU-o3Qkp54h30J\", \"name\": \"generator.pt\"},\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFJJLLP5zwMZ"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRjtz6uLkTJs"
      },
      "source": [
        "## Step 1: Select Style Type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EaetIVq8zwMa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "bd313d34-b841-4f9c-dd7b-1bf80eb163a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ncartoon026:      balanced \\ncartoon299:      big eyes \\narcane000:       for female \\narcane077:       for male \\npixar052:                  \\ncaricature039:   big mouth \\ncaricature068:   balanced  \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "#@title Select a style type { run: \"auto\", vertical-output: true, display-mode: \"both\" }\n",
        "style_type = \"cartoon026\" #@param [\"cartoon026\", \"cartoon299\", \"arcane000\", \"arcane077\", \"pixar052\", \"caricature039\", \"caricature068\"]\n",
        "\n",
        "\"\"\"\n",
        "cartoon026:      balanced\n",
        "cartoon299:      big eyes\n",
        "arcane000:       for female\n",
        "arcane077:       for male\n",
        "pixar052:\n",
        "caricature039:   big mouth\n",
        "caricature068:   balanced\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4etDz82xkTJz"
      },
      "source": [
        "## Step 2: Download Pretrained Models\n",
        "As part of this repository, we provide pretrained models. We'll download the model and save them to the folder `../checkpoint/`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLLXjePvzwMb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "799f6842-d13a-42d6-a263-aa18854dc35b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-09 04:47:26--  https://docs.google.com/uc?export=download&confirm=t&id=1NgI4mPkboYvYw3MWcdUaQhkr0OWgs9ej\n",
            "Resolving docs.google.com (docs.google.com)... 74.125.126.101, 74.125.126.139, 74.125.126.102, ...\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.126.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-04-b0-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/h58cg77edd8t1cjmnd0f3qa08n5o5aop/1667969175000/07465556750903152815/*/1NgI4mPkboYvYw3MWcdUaQhkr0OWgs9ej?e=download&uuid=e511ce52-7211-48b9-ba52-73a905b26ed3 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-11-09 04:47:26--  https://doc-04-b0-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/h58cg77edd8t1cjmnd0f3qa08n5o5aop/1667969175000/07465556750903152815/*/1NgI4mPkboYvYw3MWcdUaQhkr0OWgs9ej?e=download&uuid=e511ce52-7211-48b9-ba52-73a905b26ed3\n",
            "Resolving doc-04-b0-docs.googleusercontent.com (doc-04-b0-docs.googleusercontent.com)... 172.253.114.132, 2607:f8b0:4001:c22::84\n",
            "Connecting to doc-04-b0-docs.googleusercontent.com (doc-04-b0-docs.googleusercontent.com)|172.253.114.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1201660560 (1.1G) [application/x-zip]\n",
            "Saving to: ‘/VToonify/checkpoint/encoder.pt’\n",
            "\n",
            "/VToonify/checkpoin 100%[===================>]   1.12G  65.3MB/s    in 21s     \n",
            "\n",
            "2022-11-09 04:47:47 (55.6 MB/s) - ‘/VToonify/checkpoint/encoder.pt’ saved [1201660560/1201660560]\n",
            "\n",
            "--2022-11-09 04:47:51--  https://docs.google.com/uc?export=download&confirm=&id=1jY0mTjVB8njDh6e0LP_2UxuRK3MnjoIR\n",
            "Resolving docs.google.com (docs.google.com)... 74.125.126.101, 74.125.126.139, 74.125.126.102, ...\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.126.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-14-b0-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/1u96002eb5eih8gs63fblgqh6a9ght86/1667969250000/07465556750903152815/*/1jY0mTjVB8njDh6e0LP_2UxuRK3MnjoIR?e=download&uuid=63cf1813-f3bc-4187-a46e-4cb4b2fac113 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-11-09 04:47:54--  https://doc-14-b0-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/1u96002eb5eih8gs63fblgqh6a9ght86/1667969250000/07465556750903152815/*/1jY0mTjVB8njDh6e0LP_2UxuRK3MnjoIR?e=download&uuid=63cf1813-f3bc-4187-a46e-4cb4b2fac113\n",
            "Resolving doc-14-b0-docs.googleusercontent.com (doc-14-b0-docs.googleusercontent.com)... 172.253.114.132, 2607:f8b0:4001:c22::84\n",
            "Connecting to doc-14-b0-docs.googleusercontent.com (doc-14-b0-docs.googleusercontent.com)|172.253.114.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 53289463 (51M) [application/octet-stream]\n",
            "Saving to: ‘/VToonify/checkpoint/faceparsing.pth’\n",
            "\n",
            "/VToonify/checkpoin 100%[===================>]  50.82M   187MB/s    in 0.3s    \n",
            "\n",
            "2022-11-09 04:47:54 (187 MB/s) - ‘/VToonify/checkpoint/faceparsing.pth’ saved [53289463/53289463]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# download pSp encoder and face parsinf network\n",
        "path = MODEL_PATHS[\"encoder\"]\n",
        "download_command = get_download_model_command(file_id=path[\"id\"], file_name=path[\"name\"])\n",
        "!{download_command}\n",
        "path = MODEL_PATHS[\"faceparsing\"]\n",
        "download_command = get_download_model_command(file_id=path[\"id\"], file_name=path[\"name\"])\n",
        "!{download_command}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQ31J_m7kTJ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "081c8143-95d4-4b51-e40c-40bae50787bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-09 04:48:12--  https://docs.google.com/uc?export=download&confirm=t&id=1YJYODh_vEyUrL0q02okjcicpJhdYY8An\n",
            "Resolving docs.google.com (docs.google.com)... 173.194.196.139, 173.194.196.100, 173.194.196.101, ...\n",
            "Connecting to docs.google.com (docs.google.com)|173.194.196.139|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-0g-b0-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/r1n89sr4b6fhislt56cucr1153n2s0lj/1667969250000/07465556750903152815/*/1YJYODh_vEyUrL0q02okjcicpJhdYY8An?e=download&uuid=6963edb2-7a32-4495-90e5-772d5ce055e9 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-11-09 04:48:12--  https://doc-0g-b0-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/r1n89sr4b6fhislt56cucr1153n2s0lj/1667969250000/07465556750903152815/*/1YJYODh_vEyUrL0q02okjcicpJhdYY8An?e=download&uuid=6963edb2-7a32-4495-90e5-772d5ce055e9\n",
            "Resolving doc-0g-b0-docs.googleusercontent.com (doc-0g-b0-docs.googleusercontent.com)... 172.253.114.132, 2607:f8b0:4001:c22::84\n",
            "Connecting to doc-0g-b0-docs.googleusercontent.com (doc-0g-b0-docs.googleusercontent.com)|172.253.114.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 666594870 (636M) [application/x-zip]\n",
            "Saving to: ‘/VToonify/checkpoint/cartoon026_generator.pt’\n",
            "\n",
            "/VToonify/checkpoin 100%[===================>] 635.71M  94.5MB/s    in 8.2s    \n",
            "\n",
            "2022-11-09 04:48:21 (77.9 MB/s) - ‘/VToonify/checkpoint/cartoon026_generator.pt’ saved [666594870/666594870]\n",
            "\n",
            "--2022-11-09 04:48:24--  https://docs.google.com/uc?export=download&confirm=&id=1BuCeLk3ASZcoHlbfT28qNru4r5f-hErr\n",
            "Resolving docs.google.com (docs.google.com)... 173.194.196.139, 173.194.196.100, 173.194.196.101, ...\n",
            "Connecting to docs.google.com (docs.google.com)|173.194.196.139|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-04-b0-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/5m7jaopdoj482v1tm2lgkgnb3af8mtit/1667969250000/07465556750903152815/*/1BuCeLk3ASZcoHlbfT28qNru4r5f-hErr?e=download&uuid=52481536-f0b5-46ed-af24-99cd75095cda [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-11-09 04:48:27--  https://doc-04-b0-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/5m7jaopdoj482v1tm2lgkgnb3af8mtit/1667969250000/07465556750903152815/*/1BuCeLk3ASZcoHlbfT28qNru4r5f-hErr?e=download&uuid=52481536-f0b5-46ed-af24-99cd75095cda\n",
            "Resolving doc-04-b0-docs.googleusercontent.com (doc-04-b0-docs.googleusercontent.com)... 172.253.114.132, 2607:f8b0:4001:c22::84\n",
            "Connecting to doc-04-b0-docs.googleusercontent.com (doc-04-b0-docs.googleusercontent.com)|172.253.114.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11714990 (11M) [application/octet-stream]\n",
            "Saving to: ‘/VToonify/checkpoint/cartoon_exstyle_code.npy’\n",
            "\n",
            "/VToonify/checkpoin 100%[===================>]  11.17M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2022-11-09 04:48:28 (108 MB/s) - ‘/VToonify/checkpoint/cartoon_exstyle_code.npy’ saved [11714990/11714990]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# download vtoonify\n",
        "path = MODEL_PATHS[style_type]\n",
        "download_command = get_download_model_command(file_id=path[\"id\"], file_name = style_type + '_' + path[\"name\"])\n",
        "!{download_command}\n",
        "# download extrinsic style code\n",
        "path = MODEL_PATHS[style_type[:-3]+'_exstyle']\n",
        "download_command = get_download_model_command(file_id=path[\"id\"], file_name = style_type[:-3] + '_' + path[\"name\"])\n",
        "!{download_command}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAWrUehTkTKJ"
      },
      "source": [
        "## Step 3: Load Pretrained Model\n",
        "We assume that you have downloaded all relevant models and placed them in the directory defined by the above dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBgNcA7XzwMb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8385e767-64c8-4cd4-c245-a4feecc5f44e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model successfully loaded!\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5],std=[0.5,0.5,0.5]),\n",
        "    ])\n",
        "\n",
        "vtoonify = VToonify(backbone = 'dualstylegan')\n",
        "vtoonify.load_state_dict(torch.load(os.path.join(MODEL_DIR, style_type+'_generator.pt'), map_location=lambda storage, loc: storage)['g_ema'])\n",
        "vtoonify.to(device)\n",
        "\n",
        "parsingpredictor = BiSeNet(n_classes=19)\n",
        "parsingpredictor.load_state_dict(torch.load(os.path.join(MODEL_DIR, 'faceparsing.pth'), map_location=lambda storage, loc: storage))\n",
        "parsingpredictor.to(device).eval()\n",
        "\n",
        "modelname = './checkpoint/shape_predictor_68_face_landmarks.dat'\n",
        "if not os.path.exists(modelname):\n",
        "    import wget, bz2\n",
        "    wget.download('http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2', modelname+'.bz2')\n",
        "    zipfile = bz2.BZ2File(modelname+'.bz2')\n",
        "    data = zipfile.read()\n",
        "    open(modelname, 'wb').write(data)\n",
        "landmarkpredictor = dlib.shape_predictor(modelname)\n",
        "\n",
        "pspencoder = load_psp_standalone(os.path.join(MODEL_DIR, 'encoder.pt'), device)\n",
        "\n",
        "exstyles = np.load(os.path.join(MODEL_DIR, style_type[:-3]+'_exstyle_code.npy'), allow_pickle='TRUE').item()\n",
        "stylename = list(exstyles.keys())[int(style_type[-3:])]\n",
        "exstyle = torch.tensor(exstyles[stylename]).to(device)\n",
        "with torch.no_grad():\n",
        "    exstyle = vtoonify.zplus2wplus(exstyle)\n",
        "\n",
        "print('Model successfully loaded!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4weLFoPbkTKZ"
      },
      "source": [
        "## Step 4: Image Toonification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6oqf8JwzK0K"
      },
      "source": [
        "### Visualize and Rescale Input\n",
        "We rescale the input image to make it fit our pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2H9zFLJkTKa"
      },
      "outputs": [],
      "source": [
        "image_path = '/content/1.jpeg'\n",
        "original_image = load_image(image_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lbLKtl-kTKc"
      },
      "outputs": [],
      "source": [
        "visualize(original_image[0], 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJ9Ce1aYzmFF"
      },
      "outputs": [],
      "source": [
        "frame = cv2.imread(image_path)\n",
        "frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "scale = 1\n",
        "kernel_1d = np.array([[0.125],[0.375],[0.375],[0.125]])\n",
        "# We detect the face in the image, and resize the image so that the eye distance is 64 pixels.\n",
        "# Centered on the eyes, we crop the image to almost 400x400 (based on args.padding).\n",
        "paras = get_video_crop_parameter(frame, landmarkpredictor, padding=[200,200,200,200])\n",
        "if paras is not None:\n",
        "    h,w,top,bottom,left,right,scale = paras\n",
        "    H, W = int(bottom-top), int(right-left)\n",
        "    # for HR image, we apply gaussian blur to it to avoid over-sharp stylization results\n",
        "    if scale <= 0.75:\n",
        "        frame = cv2.sepFilter2D(frame, -1, kernel_1d, kernel_1d)\n",
        "    if scale <= 0.375:\n",
        "        frame = cv2.sepFilter2D(frame, -1, kernel_1d, kernel_1d)\n",
        "    frame = cv2.resize(frame, (w, h))[top:bottom, left:right]\n",
        "    x = transform(frame).unsqueeze(dim=0).to(device)\n",
        "else:\n",
        "    print('no face detected!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hUBAfodh5PaM"
      },
      "outputs": [],
      "source": [
        "visualize(x[0].cpu(), 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0BmXzu1kTKg"
      },
      "source": [
        "### Perform Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnCKxP8FzwMd"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    I = align_face(frame, landmarkpredictor)\n",
        "    I = transform(I).unsqueeze(dim=0).to(device)\n",
        "    s_w = pspencoder(I)\n",
        "    s_w = vtoonify.zplus2wplus(s_w)\n",
        "    s_w[:,:7] = exstyle[:,:7]\n",
        "    # parsing network works best on 512x512 images, so we predict parsing maps on upsmapled frames\n",
        "    # followed by downsampling the parsing maps\n",
        "    x_p = F.interpolate(parsingpredictor(2*(F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)))[0],\n",
        "                        scale_factor=0.5, recompute_scale_factor=False).detach()\n",
        "    # we give parsing maps lower weight (1/16)\n",
        "    inputs = torch.cat((x, x_p/16.), dim=1)\n",
        "    # d_s has no effect when backbone is toonify\n",
        "    y_tilde = vtoonify(inputs, s_w.repeat(inputs.size(0), 1, 1), d_s = 0.5)\n",
        "    y_tilde = torch.clamp(y_tilde, -1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYzQZT8czwMe"
      },
      "outputs": [],
      "source": [
        "visualize(y_tilde[0].cpu(), 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjCvUNrWzwMe"
      },
      "source": [
        "## Step 5: Video Toonification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbsH8H3nzwMe"
      },
      "source": [
        "### Visualize and Rescale Input\n",
        "We rescale the input video to make it fit our pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7V38qIi7zwMe"
      },
      "outputs": [],
      "source": [
        "video_path = '/content/IMG_9685.mp4'\n",
        "video_cap = cv2.VideoCapture(video_path)\n",
        "num = int(video_cap.get(7))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWG8-hsAzwMe"
      },
      "outputs": [],
      "source": [
        "success, frame = video_cap.read()\n",
        "if success == False:\n",
        "    assert('load video frames error')\n",
        "frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kec029XTzwMf"
      },
      "outputs": [],
      "source": [
        "visualize(transform(frame), 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9FAXp2xzwMf"
      },
      "outputs": [],
      "source": [
        "scale = 1\n",
        "kernel_1d = np.array([[0.125],[0.375],[0.375],[0.125]])\n",
        "# We proprocess the video by detecting the face in the first frame,\n",
        "# and resizing the frame so that the eye distance is 64 pixels.\n",
        "# Centered on the eyes, we crop the first frame to almost 400x400 (based on args.padding).\n",
        "# All other frames use the same resizing and cropping parameters as the first frame.\n",
        "paras = get_video_crop_parameter(frame, landmarkpredictor, padding=[200,200,200,200])\n",
        "if paras is None:\n",
        "    print('no face detected!')\n",
        "else:\n",
        "    h,w,top,bottom,left,right,scale = paras\n",
        "    H, W = int(bottom-top), int(right-left)\n",
        "# for HR video, we apply gaussian blur to the frames to avoid flickers caused by bilinear downsampling\n",
        "# this can also prevent over-sharp stylization results.\n",
        "if scale <= 0.75:\n",
        "    frame = cv2.sepFilter2D(frame, -1, kernel_1d, kernel_1d)\n",
        "if scale <= 0.375:\n",
        "    frame = cv2.sepFilter2D(frame, -1, kernel_1d, kernel_1d)\n",
        "frame = cv2.resize(frame, (w, h))[top:bottom, left:right]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGA_os5gzwMf"
      },
      "outputs": [],
      "source": [
        "visualize(transform(frame), 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XF_Uk0lKzwMf"
      },
      "source": [
        "### Perform Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HG1FxtPzzwMf"
      },
      "outputs": [],
      "source": [
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "videoWriter = cv2.VideoWriter(os.path.join(OUT_DIR, 'result.mp4'), fourcc, video_cap.get(5), (4*W, 4*H))\n",
        "batch_size = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30bmxfpbzwMf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91af94a5-f203-4cb6-a3e0-2208f4c95ca3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 207/207 [01:34<00:00,  2.20it/s]\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    batch_frames = []\n",
        "    for i in tqdm(range(num)):\n",
        "        if i == 0:\n",
        "            I = align_face(frame, landmarkpredictor)\n",
        "            I = transform(I).unsqueeze(dim=0).to(device)\n",
        "            s_w = pspencoder(I)\n",
        "            s_w = vtoonify.zplus2wplus(s_w)\n",
        "            s_w[:,:7] = exstyle[:,:7]\n",
        "        else:\n",
        "            success, frame = video_cap.read()\n",
        "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            if scale <= 0.75:\n",
        "                frame = cv2.sepFilter2D(frame, -1, kernel_1d, kernel_1d)\n",
        "            if scale <= 0.375:\n",
        "                frame = cv2.sepFilter2D(frame, -1, kernel_1d, kernel_1d)\n",
        "            frame = cv2.resize(frame, (w, h))[top:bottom, left:right]\n",
        "\n",
        "        batch_frames += [transform(frame).unsqueeze(dim=0).to(device)]\n",
        "\n",
        "        if len(batch_frames) == batch_size or (i+1) == num:\n",
        "            x = torch.cat(batch_frames, dim=0)\n",
        "            batch_frames = []\n",
        "            # parsing network works best on 512x512 images, so we predict parsing maps on upsmapled frames\n",
        "            # followed by downsampling the parsing maps\n",
        "            x_p = F.interpolate(parsingpredictor(2*(F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)))[0],\n",
        "                            scale_factor=0.5, recompute_scale_factor=False).detach()\n",
        "            # we give parsing maps lower weight (1/16)\n",
        "            inputs = torch.cat((x, x_p/16.), dim=1)\n",
        "            # d_s has no effect when backbone is toonify\n",
        "            y_tilde = vtoonify(inputs, s_w.repeat(inputs.size(0), 1, 1), d_s = 0.5)\n",
        "            y_tilde = torch.clamp(y_tilde, -1, 1)\n",
        "            for k in range(y_tilde.size(0)):\n",
        "                videoWriter.write(tensor2cv2(y_tilde[k].cpu()))\n",
        "videoWriter.release()\n",
        "video_cap.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJeDEh-TzwMg"
      },
      "outputs": [],
      "source": [
        "viz = torchvision.utils.make_grid(y_tilde, 2, 2)\n",
        "visualize(viz.cpu(), 120)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aF3boImzzwMg"
      },
      "source": [
        "### Find the stylized video in `./output/result.mp4`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.download('./output/result.mp4'). /content/IMG_9685.mp4\n",
        "files.down"
      ],
      "metadata": {
        "id": "pwVcXvkV3Y52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dt9fQiLozwMg"
      },
      "source": [
        "# PART III - Style control with VToonify-Dsd model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hWqNQHOzwMg"
      },
      "source": [
        "## Step 1: Download Pretrained Models\n",
        "As part of this repository, we provide pretrained models. We'll download the model and save them to the folder `../checkpoint/`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1UVTjmVzwMh"
      },
      "outputs": [],
      "source": [
        "# if you haved downloaded the encoder and faceparsing model in PART I, skip this step\n",
        "if False:\n",
        "    path = MODEL_PATHS[\"encoder\"]\n",
        "    download_command = get_download_model_command(file_id=path[\"id\"], file_name=path[\"name\"])\n",
        "    !{download_command}\n",
        "    path = MODEL_PATHS[\"faceparsing\"]\n",
        "    download_command = get_download_model_command(file_id=path[\"id\"], file_name=path[\"name\"])\n",
        "    !{download_command}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R49HXW3KzwMh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e4ce1ab-3d0e-41bc-ec95-0490efcd5cd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-09 05:28:25--  https://docs.google.com/uc?export=download&confirm=&id=1BuCeLk3ASZcoHlbfT28qNru4r5f-hErr\n",
            "Resolving docs.google.com (docs.google.com)... 74.125.201.100, 74.125.201.113, 74.125.201.101, ...\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.201.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-04-b0-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/uqjennmdvqsjdvisfh15u9ouebeb1pe3/1667971650000/07465556750903152815/*/1BuCeLk3ASZcoHlbfT28qNru4r5f-hErr?e=download&uuid=1d7b57d3-f28a-4ef8-9c83-9c0181e40a1c [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-11-09 05:28:28--  https://doc-04-b0-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/uqjennmdvqsjdvisfh15u9ouebeb1pe3/1667971650000/07465556750903152815/*/1BuCeLk3ASZcoHlbfT28qNru4r5f-hErr?e=download&uuid=1d7b57d3-f28a-4ef8-9c83-9c0181e40a1c\n",
            "Resolving doc-04-b0-docs.googleusercontent.com (doc-04-b0-docs.googleusercontent.com)... 172.217.214.132, 2607:f8b0:4001:c05::84\n",
            "Connecting to doc-04-b0-docs.googleusercontent.com (doc-04-b0-docs.googleusercontent.com)|172.217.214.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11714990 (11M) [application/octet-stream]\n",
            "Saving to: ‘/VToonify/checkpoint/cartoon_exstyle_code.npy’\n",
            "\n",
            "/VToonify/checkpoin 100%[===================>]  11.17M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2022-11-09 05:28:28 (223 MB/s) - ‘/VToonify/checkpoint/cartoon_exstyle_code.npy’ saved [11714990/11714990]\n",
            "\n",
            "--2022-11-09 05:28:29--  https://docs.google.com/uc?export=download&confirm=t&id=11s0hwhZWTLacMAzZH4OU-o3Qkp54h30J\n",
            "Resolving docs.google.com (docs.google.com)... 74.125.201.100, 74.125.201.113, 74.125.201.101, ...\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.201.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-00-b0-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/bcsuogaioq9gbcrefcbe1hefq9akcn09/1667971650000/07465556750903152815/*/11s0hwhZWTLacMAzZH4OU-o3Qkp54h30J?e=download&uuid=72d8dcc1-1947-4745-854f-37f386bc0fb5 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-11-09 05:28:29--  https://doc-00-b0-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/bcsuogaioq9gbcrefcbe1hefq9akcn09/1667971650000/07465556750903152815/*/11s0hwhZWTLacMAzZH4OU-o3Qkp54h30J?e=download&uuid=72d8dcc1-1947-4745-854f-37f386bc0fb5\n",
            "Resolving doc-00-b0-docs.googleusercontent.com (doc-00-b0-docs.googleusercontent.com)... 172.217.214.132, 2607:f8b0:4001:c05::84\n",
            "Connecting to doc-00-b0-docs.googleusercontent.com (doc-00-b0-docs.googleusercontent.com)|172.217.214.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 666594870 (636M) [application/x-zip]\n",
            "Saving to: ‘/VToonify/checkpoint/cartoon_generator.pt’\n",
            "\n",
            "/VToonify/checkpoin 100%[===================>] 635.71M  57.6MB/s    in 7.2s    \n",
            "\n",
            "2022-11-09 05:28:36 (88.6 MB/s) - ‘/VToonify/checkpoint/cartoon_generator.pt’ saved [666594870/666594870]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# download the style code and the vtoonify-Dsd\n",
        "path = MODEL_PATHS['cartoon_exstyle']\n",
        "download_command = get_download_model_command(file_id=path[\"id\"], file_name = 'cartoon_exstyle_code.npy')\n",
        "!{download_command}\n",
        "path = MODEL_PATHS['cartoon']\n",
        "download_command = get_download_model_command(file_id=path[\"id\"], file_name = 'cartoon_generator.pt')\n",
        "!{download_command}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ju-b8ivNzwMh"
      },
      "source": [
        "## Step 2: Load Pretrained Model\n",
        "We assume that you have downloaded all relevant models and placed them in the directory defined by the above dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3FRjygi8zwMh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7c7a0e8-b96f-4501-8035-125aaca5ca9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model successfully loaded!\n"
          ]
        }
      ],
      "source": [
        "# if you haved load the models in PART I, skip this step, or set False to True\n",
        "if False:\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5],std=[0.5,0.5,0.5]),\n",
        "        ])\n",
        "\n",
        "    parsingpredictor = BiSeNet(n_classes=19)\n",
        "    parsingpredictor.load_state_dict(torch.load(os.path.join(MODEL_DIR, 'faceparsing.pth'), map_location=lambda storage, loc: storage))\n",
        "    parsingpredictor.to(device).eval()\n",
        "\n",
        "    modelname = './checkpoint/shape_predictor_68_face_landmarks.dat'\n",
        "    if not os.path.exists(modelname):\n",
        "        wget.download('http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2', modelname+'.bz2')\n",
        "        zipfile = bz2.BZ2File(modelname+'.bz2')\n",
        "        data = zipfile.read()\n",
        "        open(modelname, 'wb').write(data)\n",
        "    landmarkpredictor = dlib.shape_predictor(modelname)\n",
        "\n",
        "    pspencoder = load_psp_standalone(os.path.join(MODEL_DIR, 'encoder.pt'), device)\n",
        "\n",
        "vtoonify = VToonify(backbone = 'dualstylegan')\n",
        "vtoonify.load_state_dict(torch.load(os.path.join(MODEL_DIR, 'cartoon_generator.pt'), map_location=lambda storage, loc: storage)['g_ema'])\n",
        "vtoonify.to(device)\n",
        "\n",
        "exstyles = np.load(os.path.join(MODEL_DIR, 'cartoon_exstyle_code.npy'), allow_pickle='TRUE').item()\n",
        "styles = []\n",
        "with torch.no_grad():\n",
        "    for stylename in exstyles.keys():\n",
        "        exstyle = torch.tensor(exstyles[stylename]).to(device)\n",
        "        exstyle = vtoonify.zplus2wplus(exstyle)\n",
        "        styles += [exstyle]\n",
        "exstyles = torch.cat(styles, dim=0)\n",
        "\n",
        "print('Model successfully loaded!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skayaztpzwMh"
      },
      "source": [
        "## Step 3: Image Toonification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYcmhop8zwMh"
      },
      "source": [
        "### Visualize and Rescale Input\n",
        "We rescale the input image to make it fit our pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9x591jNzwMi"
      },
      "outputs": [],
      "source": [
        "image_path = '/content/1.jpeg'\n",
        "original_image = load_image(image_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKXXNqekzwMi"
      },
      "outputs": [],
      "source": [
        "visualize(original_image[0], 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96d102HjzwMi"
      },
      "outputs": [],
      "source": [
        "frame = cv2.imread(image_path)\n",
        "frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "scale = 1\n",
        "kernel_1d = np.array([[0.125],[0.375],[0.375],[0.125]])\n",
        "# We detect the face in the image, and resize the image so that the eye distance is 64 pixels.\n",
        "# Centered on the eyes, we crop the image to almost 400x400 (based on args.padding).\n",
        "paras = get_video_crop_parameter(frame, landmarkpredictor, padding=[200,200,200,200])\n",
        "if paras is not None:\n",
        "    h,w,top,bottom,left,right,scale = paras\n",
        "    H, W = int(bottom-top), int(right-left)\n",
        "    # for HR image, we apply gaussian blur to it to avoid over-sharp stylization results\n",
        "    if scale <= 0.75:\n",
        "        frame = cv2.sepFilter2D(frame, -1, kernel_1d, kernel_1d)\n",
        "    if scale <= 0.375:\n",
        "        frame = cv2.sepFilter2D(frame, -1, kernel_1d, kernel_1d)\n",
        "    frame = cv2.resize(frame, (w, h))[top:bottom, left:right]\n",
        "    x = transform(frame).unsqueeze(dim=0).to(device)\n",
        "else:\n",
        "    print('no face detected!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uW8sPnwkzwMi"
      },
      "outputs": [],
      "source": [
        "visualize(x[0].cpu(), 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2yYa9XjmI_Ov"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iMk0ZuazwMi"
      },
      "source": [
        "### Select style image\n",
        "\n",
        "Select the style index (the mapping between index and style image is defined [here](https://github.com/williamyang1991/DualStyleGAN/blob/main/doc_images/cartoon_overview.jpg))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3IfNjdHzwMi"
      },
      "outputs": [],
      "source": [
        "style_id = [8, 26, 64, 153, 299]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AhjbJJ1zwMj"
      },
      "source": [
        "### Style transfer with different cartoon structure styles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5POMJ5YkTKl"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    I = align_face(frame, landmarkpredictor)\n",
        "    I = transform(I).unsqueeze(dim=0).to(device)\n",
        "    s_w = pspencoder(I)\n",
        "    s_w = vtoonify.zplus2wplus(s_w).repeat(len(style_id), 1, 1)\n",
        "    s_w[:,:7] = exstyles[style_id,:7]\n",
        "    x = x.repeat(len(style_id), 1, 1, 1)\n",
        "    # parsing network works best on 512x512 images, so we predict parsing maps on upsmapled frames\n",
        "    # followed by downsampling the parsing maps\n",
        "    x_p = F.interpolate(parsingpredictor(2*(F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)))[0],\n",
        "                        scale_factor=0.5, recompute_scale_factor=False).detach()\n",
        "    # we give parsing maps lower weight (1/16)\n",
        "    inputs = torch.cat((x, x_p/16.), dim=1)\n",
        "    # d_s has no effect when backbone is toonify\n",
        "    y_tilde = vtoonify(inputs, s_w, d_s = 0.6)\n",
        "    y_tilde = torch.clamp(y_tilde, -1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsHq90J1zwMj"
      },
      "outputs": [],
      "source": [
        "viz = torchvision.utils.make_grid(y_tilde, 5, 2)\n",
        "visualize(viz.cpu(), 120)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HJ-gtKrzwMj"
      },
      "source": [
        "### Navigation with different style degree to achieve flexible style manipulation\n",
        "\n",
        "Users are suggested to try different style degrees to find the ideal results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Q9nk7M0zwMj"
      },
      "outputs": [],
      "source": [
        "results = []\n",
        "with torch.no_grad():\n",
        "    for i in range(5):\n",
        "        d_s = i / 4.0\n",
        "        y_tilde = vtoonify(inputs, s_w, d_s = d_s)\n",
        "        y_tilde = torch.clamp(y_tilde, -1, 1)\n",
        "        results += [y_tilde.cpu()]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vis = torchvision.utils.make_grid(torch.cat(results, dim=0), 5, 2)\n",
        "visualize(vis, 120)"
      ],
      "metadata": {
        "id": "qMC8_NkuALeF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "aF3boImzzwMg"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "psp_env",
      "language": "python",
      "name": "psp_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}